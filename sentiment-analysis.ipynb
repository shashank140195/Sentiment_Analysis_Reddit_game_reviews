{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport joblib\nimport os # setting working directory\nimport sklearn as sk\nfrom tabulate import tabulate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import f1_score\nfrom statistics import harmonic_mean\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-05T01:45:23.266255Z","iopub.execute_input":"2021-12-05T01:45:23.266587Z","iopub.status.idle":"2021-12-05T01:45:23.280640Z","shell.execute_reply.started":"2021-12-05T01:45:23.266551Z","shell.execute_reply":"2021-12-05T01:45:23.279115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read in the data from file\n# train = pd.read_csv('../input/reddit-data/reddit_training.csv')\ntrain = pd.read_csv('../input/dataset/reddit_training.csv')\n# train = train.drop('Controls', axis=1)\n# train = train.drop('Graphics', axis=1)\n# train = train.drop('Story', axis=1)\n# train = train.drop('Bugs', axis=1)\n\n# print out the first few lines\n#train.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:45:23.312910Z","iopub.execute_input":"2021-12-05T01:45:23.313567Z","iopub.status.idle":"2021-12-05T01:45:23.334185Z","shell.execute_reply.started":"2021-12-05T01:45:23.313533Z","shell.execute_reply":"2021-12-05T01:45:23.332710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read in the data from file\n# test = pd.read_csv('../input/reddit-data/reddit_testing.csv')\ntest = pd.read_csv('../input/dataset/reddit_testing.csv')\n# test = test.drop('Controls', axis=1)\n# test = test.drop('Graphics', axis=1)\n# test = test.drop('Story', axis=1)\n# test = test.drop('Bugs', axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:45:23.336521Z","iopub.execute_input":"2021-12-05T01:45:23.337154Z","iopub.status.idle":"2021-12-05T01:45:23.349505Z","shell.execute_reply.started":"2021-12-05T01:45:23.337117Z","shell.execute_reply":"2021-12-05T01:45:23.348683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocess the data\ndef preprocess_data(data):\n    # Convert text to lowercase and replace new lines with spaces\n    data['Overall Sentiment'] = data['Overall Sentiment'].str.strip().str.lower()\n    data['Controls'] = data['Controls'].str.strip().str.lower()\n    data['Graphics'] = data['Graphics'].str.strip().str.lower()\n    data['Story'] = data['Story'].str.strip().str.lower()\n    data['Bugs'] = data['Bugs'].str.strip().str.lower()\n    data['Comment Body'] = data['Comment Body'].str.strip().str.lower()\n    data['Comment Body'] = data['Comment Body'].str.replace(\"\\n\", \" \")\n    return data\n\n\n# call preprocess function\ntest = preprocess_data(test)\ntrain = preprocess_data(train)\n\n# define train and test sets for Overall Sentiment\ntrain_overall = train[train['Overall Sentiment'] != 'neutral']\ntest_overall = test[test['Overall Sentiment'] != 'neutral']\n\n# define train and test sets for Control Sentiment\ntrain_controls = train[train['Controls'] != 'neutral']\ntest_controls = test[test['Controls'] != 'neutral']\n\n# define train and test sets for Story Sentiment\ntrain_story = train[train['Story'] != 'neutral']\ntest_story = test[test['Story'] != 'neutral']\n\n# define train and test sets for Control Sentiment\ntrain_graphics = train[train['Graphics'] != 'neutral']\ntest_graphics = test[test['Graphics'] != 'neutral']\n\n# define train and test sets for Control Sentiment\ntrain_bugs = train[train['Bugs'] != 'neutral']\ntest_bugs = test[test['Bugs'] != 'neutral']\n\ntrain_overall.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:45:23.355779Z","iopub.execute_input":"2021-12-05T01:45:23.356500Z","iopub.status.idle":"2021-12-05T01:45:23.405099Z","shell.execute_reply.started":"2021-12-05T01:45:23.356464Z","shell.execute_reply":"2021-12-05T01:45:23.403606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##### gets n-grams\n# chooses n's for n-grams\nmin_n = 1\nmax_n = 4\n\n# sets ups n-gram calculator\n# character partition\n# ngram_calculator = CountVectorizer(ngram_range = (min_n, max_n), analyzer = 'char')\n# word partition\nngram_calculator = CountVectorizer(ngram_range = (min_n, max_n), analyzer = 'word')\nngram_calculator.fit(train_overall['Comment Body'])\n# gets ngram (count) features\nx_train_overall = ngram_calculator.transform(train_overall['Comment Body'])\nx_test_overall = ngram_calculator.transform(test_overall['Comment Body'])\n\n# redo for other facets\n# controls\n#ngram_calculator = CountVectorizer(ngram_range = (min_n, max_n), analyzer = 'word')\nngram_calculator.fit(train_controls['Comment Body'])\nx_train_controls = ngram_calculator.transform(train_controls['Comment Body'])\nx_test_controls = ngram_calculator.transform(test_controls['Comment Body'])\n# graphics\n#ngram_calculator = CountVectorizer(ngram_range = (min_n, max_n), analyzer = 'word')\nngram_calculator.fit(train_graphics['Comment Body'])\nx_train_graphics = ngram_calculator.transform(train_graphics['Comment Body'])\nx_test_graphics = ngram_calculator.transform(test_graphics['Comment Body'])\n# story\n#ngram_calculator = CountVectorizer(ngram_range = (min_n, max_n), analyzer = 'word')\nngram_calculator.fit(train_story['Comment Body'])\nx_train_story = ngram_calculator.transform(train_story['Comment Body'])\nx_test_story = ngram_calculator.transform(test_story['Comment Body'])\n# bugs\n#ngram_calculator = CountVectorizer(ngram_range = (min_n, max_n), analyzer = 'word')\nngram_calculator.fit(train_bugs['Comment Body'])\nx_train_bugs = ngram_calculator.transform(train_bugs['Comment Body'])\nx_test_bugs = ngram_calculator.transform(test_bugs['Comment Body'])","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:45:23.407923Z","iopub.execute_input":"2021-12-05T01:45:23.408367Z","iopub.status.idle":"2021-12-05T01:45:25.398178Z","shell.execute_reply.started":"2021-12-05T01:45:23.408322Z","shell.execute_reply":"2021-12-05T01:45:25.397215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testin printings\n# print(train_bugs)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:45:25.399682Z","iopub.execute_input":"2021-12-05T01:45:25.400051Z","iopub.status.idle":"2021-12-05T01:45:25.404591Z","shell.execute_reply.started":"2021-12-05T01:45:25.399990Z","shell.execute_reply":"2021-12-05T01:45:25.403940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##### gets labels for overall sentiment\ny_train_overall = train_overall['Overall Sentiment']\ny_test_overall = test_overall['Overall Sentiment']\n\n##### gets labels for controls sentiment\ny_train_controls = train_controls['Controls']\ny_test_controls = test_controls['Controls']\n\n##### gets labels for graphics sentiment\ny_train_graphics = train_graphics['Graphics']\ny_test_graphics = test_graphics['Graphics']\n\n##### gets labels for story sentiment\ny_train_story = train_story['Story']\ny_test_story = test_story['Story']\n\n##### gets labels for bugs sentiment\ny_train_bugs = train_bugs['Bugs']\ny_test_bugs = test_bugs['Bugs']\n    \n# remove neutral reviews\n# y_train = y_train[y_train != 'neutral']\n# y_test = y_test[y_test != 'neutral']\n    \n# converts Positive/Negative to binary for sci-kit\nreview2bin = {'negative':0, 'positive':1}\n\ny_train_overall = [review2bin[el] for el in y_train_overall]\ny_test_overall = [review2bin[el] for el in y_test_overall]\n\ny_train_controls = [review2bin[el] for el in y_train_controls]\ny_test_controls = [review2bin[el] for el in y_test_controls]\n\ny_train_graphics = [review2bin[el] for el in y_train_graphics]\ny_test_graphics = [review2bin[el] for el in y_test_graphics]\n\ny_train_story = [review2bin[el] for el in y_train_story]\ny_test_story = [review2bin[el] for el in y_test_story]\n\ny_train_bugs = [review2bin[el] for el in y_train_bugs]\ny_test_bugs = [review2bin[el] for el in y_test_bugs]","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:45:25.406088Z","iopub.execute_input":"2021-12-05T01:45:25.406976Z","iopub.status.idle":"2021-12-05T01:45:25.423263Z","shell.execute_reply.started":"2021-12-05T01:45:25.406935Z","shell.execute_reply":"2021-12-05T01:45:25.422453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##################### splits training data sets into train/valid ##############################\nx_train_train_overall, x_train_valid_overall, y_train_train_overall, y_train_valid_overall = train_test_split(x_train_overall, y_train_overall, test_size = 0.20, random_state = 0)\n################## splits facets training data sets into train/valid ##########################\nx_train_train_controls, x_train_valid_controls, y_train_train_controls, y_train_valid_controls = train_test_split(x_train_controls, y_train_controls, test_size = 0.20, random_state = 0)\nx_train_train_graphics, x_train_valid_graphics, y_train_train_graphics, y_train_valid_graphics = train_test_split(x_train_graphics, y_train_graphics, test_size = 0.20, random_state = 0)\nx_train_train_story, x_train_valid_story, y_train_train_story, y_train_valid_story = train_test_split(x_train_story, y_train_story, test_size = 0.20, random_state = 0)\nx_train_train_bugs, x_train_valid_bugs, y_train_train_bugs, y_train_valid_bugs = train_test_split(x_train_bugs, y_train_bugs, test_size = 0.20, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:45:25.426386Z","iopub.execute_input":"2021-12-05T01:45:25.426969Z","iopub.status.idle":"2021-12-05T01:45:25.450972Z","shell.execute_reply.started":"2021-12-05T01:45:25.426917Z","shell.execute_reply":"2021-12-05T01:45:25.450126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function that fits regression model and assesses performance\ndef logistic_wrapper(x_fit, y_fit, x_performance, y_performance, alpha):\n    # runs logistic regression\n    model = LogisticRegression(C = 1/alpha, solver = 'liblinear')\n    model.fit(x_fit, y_fit)\n    \n    # calculates performance (precision, recall, F1)\n    labels = y_performance\n    predictions = model.predict(x_performance)\n    precision, recall, f1, support = precision_recall_fscore_support(labels, predictions, average ='binary')\n        \n    return f1, precision, recall, predictions","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:45:25.452871Z","iopub.execute_input":"2021-12-05T01:45:25.453261Z","iopub.status.idle":"2021-12-05T01:45:25.463489Z","shell.execute_reply.started":"2021-12-05T01:45:25.453214Z","shell.execute_reply":"2021-12-05T01:45:25.462426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is where the table needs data from for analysis\n##### fits a regression model and assesses performance\nf1, precision, recall, predictions_overall = logistic_wrapper(x_train_overall, y_train_overall, x_test_overall, y_test_overall, 0.1)\n    \n# print results\nprint('F1: ', f1)\nprint('precision: ', precision)\nprint('recall: ', recall)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:45:25.465419Z","iopub.execute_input":"2021-12-05T01:45:25.466442Z","iopub.status.idle":"2021-12-05T01:45:25.683202Z","shell.execute_reply.started":"2021-12-05T01:45:25.466402Z","shell.execute_reply":"2021-12-05T01:45:25.682125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is where the table needs data from for analysis\n##### fits a regression model and assesses performance\nf1, precision, recall, predictions_controls = logistic_wrapper(x_train_controls, y_train_controls, x_test_controls, y_test_controls, 0.1)\n    \n# print results\nprint('F1: ', f1)\nprint('precision: ', precision)\nprint('recall: ', recall)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:45:25.685409Z","iopub.execute_input":"2021-12-05T01:45:25.686142Z","iopub.status.idle":"2021-12-05T01:45:25.752605Z","shell.execute_reply.started":"2021-12-05T01:45:25.686080Z","shell.execute_reply":"2021-12-05T01:45:25.751603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is where the table needs data from for analysis\n##### fits a regression model and assesses performance\nf1, precision, recall, predictions_graphics = logistic_wrapper(x_train_graphics, y_train_graphics, x_test_graphics, y_test_graphics, 0.1)\n    \n# print results\nprint('F1: ', f1)\nprint('precision: ', precision)\nprint('recall: ', recall)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:45:25.754702Z","iopub.execute_input":"2021-12-05T01:45:25.755310Z","iopub.status.idle":"2021-12-05T01:45:25.816350Z","shell.execute_reply.started":"2021-12-05T01:45:25.755252Z","shell.execute_reply":"2021-12-05T01:45:25.815366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is where the table needs data from for analysis\n##### fits a regression model and assesses performance\nf1, precision, recall, predictions_story = logistic_wrapper(x_train_story, y_train_story, x_test_story, y_test_story, 0.1)\n    \n# print results\nprint('F1: ', f1)\nprint('precision: ', precision)\nprint('recall: ', recall)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:45:25.818352Z","iopub.execute_input":"2021-12-05T01:45:25.818910Z","iopub.status.idle":"2021-12-05T01:45:25.963307Z","shell.execute_reply.started":"2021-12-05T01:45:25.818854Z","shell.execute_reply":"2021-12-05T01:45:25.962297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is where the table needs data from for analysis\n##### fits a regression model and assesses performance\nf1, precision, recall, predictions_bugs = logistic_wrapper(x_train_bugs, y_train_bugs, x_test_bugs, y_test_bugs, 0.1)\n    \n# print results\nprint('F1: ', f1)\nprint('precision: ', precision)\nprint('recall: ', recall)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:45:25.965377Z","iopub.execute_input":"2021-12-05T01:45:25.966240Z","iopub.status.idle":"2021-12-05T01:45:26.007009Z","shell.execute_reply.started":"2021-12-05T01:45:25.965967Z","shell.execute_reply":"2021-12-05T01:45:26.006053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##### grid search for regularization constant\n# Grid of regularization constant values\nalpha_list = [0.01, 0.05, 0.1, 0.5, 1, 2, 10, 20, 100]\n\n# gets performance for each choice of regularization constant\noutput = [logistic_wrapper(x_train_train_overall, y_train_train_overall, x_train_valid_overall, y_train_valid_overall, alpha) for alpha in alpha_list]\n\n\n### tabulates and prints performance by \n# reformats output into lists of metric values\noutput = list(zip(*output))\nf1_alpha, precision_alpha, recall_alpha, predictions_alpha = [list(el) for el in output]\n\n# adds row titles\nalpha_list.insert(0,'alpha')\nf1_alpha.insert(0,'F1')\nprecision_alpha.insert(0,'precision')\nrecall_alpha.insert(0,'recall')\n\n# makes list of lists for tabulate.tabulate\ntable = [alpha_list, list(f1_alpha), precision_alpha, recall_alpha]\n\n# prints table\nprint(tabulate(table))","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:45:26.009060Z","iopub.execute_input":"2021-12-05T01:45:26.009633Z","iopub.status.idle":"2021-12-05T01:45:27.180260Z","shell.execute_reply.started":"2021-12-05T01:45:26.009578Z","shell.execute_reply":"2021-12-05T01:45:27.179315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"######## DEFINING WHICH SET TO FIND BEST ALPHA FOR ########\n# Uncomment the set of training and testing data to find the best alpha value for\nx_train = x_train_overall\ny_train = y_train_overall\nx_train_train = x_train_train_overall\nx_train_valid = x_train_valid_overall\ny_train_train = y_train_train_overall\ny_train_valid = y_train_valid_overall\n\n# x_train = x_train_controls\n# y_train = y_train_controls\n# x_train_train = x_train_train_controls\n# x_train_valid = x_train_valid_controls\n# y_train_train = y_train_train_controls\n# y_train_valid = y_train_valid_controls\n\n# x_train = x_train_graphics\n# y_train = y_train_graphics\n# x_train_train = x_train_train_graphics\n# x_train_valid = x_train_valid_graphics\n# y_train_train = y_train_train_graphics\n# y_train_valid = y_train_valid_graphics\n\n# x_train = x_train_story\n# y_train = y_train_story\n# x_train_train = x_train_train_story\n# x_train_valid = x_train_valid_story\n# y_ train_train = y_train_train_story\n# y_train_valid = y_train_valid_story\n\n# x_train = x_train_bugs\n# y_train = y_train_bugs\n# x_train_train = x_train_train_bugs\n# x_train_valid = x_train_valid_bugs\n# y_train_train = y_train_train_bugs\n# y_train_valid = y_train_valid_bugs","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:45:27.182249Z","iopub.execute_input":"2021-12-05T01:45:27.182789Z","iopub.status.idle":"2021-12-05T01:45:27.192634Z","shell.execute_reply.started":"2021-12-05T01:45:27.182736Z","shell.execute_reply":"2021-12-05T01:45:27.191671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##### Looping the table through 30 random splits to find best alpha\n# Array to keep track of average alpha Fscore\nalpha_f1_average = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n# Loop for random splits\nfor i in range(1,30):\n    x_train_train, x_train_valid, y_train_train, y_train_valid = train_test_split(x_train, y_train, test_size = 0.2)\n    \n    ##### grid search for regularization constant\n    # Grid of regularization constant values\n    alpha_list = [0.01, 0.05, 0.1, 0.5, 1, 2, 10, 20, 100]\n\n    # gets performance for each choice of regularization constant\n    output = [logistic_wrapper(x_train_train, y_train_train, x_train_valid, y_train_valid, alpha) for alpha in alpha_list]\n\n\n    ### tabulates and prints performance by \n    # reformats output into lists of metric values\n    output = list(zip(*output))\n    f1_alpha, precision_alpha, recall_alpha, predictions_alpha = [list(el) for el in output]\n\n    for count in range(0,9):\n        alpha_f1_average[count] = alpha_f1_average[count] + f1_alpha[count]\n    \n    # adds row titles\n    alpha_list.insert(0,'alpha')\n    f1_alpha.insert(0,'F1')\n    precision_alpha.insert(0,'precision')\n    recall_alpha.insert(0,'recall')\n\n    # makes list of lists for tabulate.tabulate\n    table = [alpha_list, list(f1_alpha), precision_alpha, recall_alpha]\n    \n    # prints table\n    # print(tabulate(table))\n    \n# print averages to compare manually\nalpha_list = [0.01, 0.05, 0.1, 0.5, 1, 2, 10, 20, 100]\n\n# print all averages\nmax_index = 0\nfor count in range(0,9):\n    # print(\"Alpha Value: \", alpha_list[count],\"Average F1 Score: \", alpha_f1_average[count]/30)\n    if alpha_f1_average[count] > alpha_f1_average[max_index]:\n        max_index = count\n    \n# print alpha with best average\nprint(\"Best Average Alpha: \", alpha_list[max_index], \"\\nAverage F1 Score: \", alpha_f1_average[max_index]/30)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:45:27.196640Z","iopub.execute_input":"2021-12-05T01:45:27.197197Z","iopub.status.idle":"2021-12-05T01:46:02.920966Z","shell.execute_reply.started":"2021-12-05T01:45:27.197146Z","shell.execute_reply":"2021-12-05T01:46:02.919994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###### Choost prediction set ######\nlabels = y_train_overall\n# labels = y_train_controls\n# labels = y_train_graphics\n# labels = y_train_story\n# labels = y_train_bugs\n\npredictions = predictions_overall\n# predictions = predictions_controls\n# predictions = predictions_graphics\n# predictions = predictions_story\n# predictions = predictions_bugs","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:46:02.923125Z","iopub.execute_input":"2021-12-05T01:46:02.923821Z","iopub.status.idle":"2021-12-05T01:46:02.930009Z","shell.execute_reply.started":"2021-12-05T01:46:02.923771Z","shell.execute_reply":"2021-12-05T01:46:02.929006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##### accessing examples for error analysis\n\n# obtains list of false positive and negative indices\nFPs = [i for i in range(len(predictions)) if predictions[i] == 1 and labels[i] == 0]\nFNs = [i for i in range(len(predictions)) if predictions[i] == 0 and labels[i] == 1]\n\nprint(FPs)\nprint(FNs)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:46:02.932085Z","iopub.execute_input":"2021-12-05T01:46:02.932805Z","iopub.status.idle":"2021-12-05T01:46:02.958409Z","shell.execute_reply.started":"2021-12-05T01:46:02.932754Z","shell.execute_reply":"2021-12-05T01:46:02.957112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Testing a single review ###\n# function that fits regression model and assesses performance\ndef testing_wrapper(training, x_fit, y_fit, review, alpha):\n    \n    ##### gets n-grams\n\n    # sets ups n-gram calculator\n    # character partition\n    # ngram_calculator = CountVectorizer(ngram_range = (min_n, max_n), analyzer = 'char')\n    # word partition\n    ngram_calculator = CountVectorizer(ngram_range = (min_n, max_n), analyzer = 'word')\n    ngram_calculator.fit(training['Comment Body'])\n    # gets ngram (count) features\n    x_review = ngram_calculator.transform([review])\n    \n    # runs logistic regression\n    model = LogisticRegression(C = 1/alpha, solver = 'liblinear')\n    model.fit(x_fit, y_fit)\n    \n    # calculates prediction\n    predictions = model.predict(x_review)\n        \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:46:02.960656Z","iopub.execute_input":"2021-12-05T01:46:02.961250Z","iopub.status.idle":"2021-12-05T01:46:02.970501Z","shell.execute_reply.started":"2021-12-05T01:46:02.961207Z","shell.execute_reply":"2021-12-05T01:46:02.969535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Wrapper to generate predictions for a review\ndef prediction_wrapper(review):\n    predictions_overall = testing_wrapper(train_overall, x_train_overall, y_train_overall, review, 0.1)\n    predictions_controls = testing_wrapper(train_controls, x_train_controls, y_train_controls, review, 0.1)\n    predictions_graphics = testing_wrapper(train_graphics, x_train_graphics, y_train_graphics, review, 0.1)\n    predictions_story = testing_wrapper(train_story, x_train_story, y_train_story, review, 0.1)\n    predictions_bugs = testing_wrapper(train_bugs, x_train_bugs, y_train_bugs, review, 0.1)\n    print(\"Review: \", review)\n    print(\"Overall Sentiment Prediction: \", predictions_overall)\n    print(\"Controls Sentiment Prediction: \", predictions_controls)\n    print(\"Graphics Sentiment Prediction: \", predictions_graphics)\n    print(\"Story Sentiment Prediction: \", predictions_story)\n    print(\"Bugs Sentiment Prediction: \", predictions_bugs)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:46:02.972344Z","iopub.execute_input":"2021-12-05T01:46:02.972927Z","iopub.status.idle":"2021-12-05T01:46:02.985532Z","shell.execute_reply.started":"2021-12-05T01:46:02.972886Z","shell.execute_reply":"2021-12-05T01:46:02.984517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"review = \"This was a great game with bad controls\"\nprediction_wrapper(review)\n\nreview = \"I did not enjoy this game. The graphics were awesome, but it was very buggy\"\nprediction_wrapper(review)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:46:02.987346Z","iopub.execute_input":"2021-12-05T01:46:02.987923Z","iopub.status.idle":"2021-12-05T01:46:07.019542Z","shell.execute_reply.started":"2021-12-05T01:46:02.987882Z","shell.execute_reply":"2021-12-05T01:46:07.018318Z"},"trusted":true},"execution_count":null,"outputs":[]}]}